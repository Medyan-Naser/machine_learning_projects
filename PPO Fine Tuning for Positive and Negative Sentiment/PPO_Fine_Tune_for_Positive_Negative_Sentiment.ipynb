{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user torch==2.3.1 torchtext==0.17.2\n",
    "!pip install --user datasets==3.2.0\n",
    "!pip install --user trl==0.11\n",
    "!pip install --user transformers==4.43.4\n",
    "!pip install --user nltk==3.9.1 rouge_score==0.1.2\n",
    "!pip install --user matplotlib==3.10.0 \n",
    "!pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e64a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer,AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "import os\n",
    "\n",
    "import tarfile\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Disable warnings for a cleaner notebook or console experience\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842df524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Save a dictionary to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The dictionary to save.\n",
    "        file_path (str): The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Data successfully saved to {file_path}\")\n",
    "    \n",
    "    \n",
    "def load_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The data loaded from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8365fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_to_length(tensor, length, pad_token_id):\n",
    "    padding_length = length - tensor.size(0)\n",
    "    if padding_length > 0:\n",
    "        padding = torch.full((padding_length,), pad_token_id, dtype=torch.long, device=tensor.device)\n",
    "        return torch.cat((tensor, padding))\n",
    "    return tensor\n",
    "\n",
    "def pad_list_to_batch_size(tensors, batch_size, pad_token_id):\n",
    "    max_length = max(t.size(0) for t in tensors)\n",
    "    padded_tensors = [pad_sequence_to_length(t, max_length, pad_token_id) for t in tensors]\n",
    "\n",
    "    # Add additional padding-only tensors if needed\n",
    "    while len(padded_tensors) < batch_size:\n",
    "        padded_tensors.append(torch.full((max_length,), pad_token_id, dtype=torch.long, device=tensors[0].device))\n",
    "\n",
    "    return padded_tensors[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c23e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ppo_stats(stats, related_to_objective=False):\n",
    "    print(\"PPO Training Statistics\\n\")\n",
    "\n",
    "    if related_to_objective:\n",
    "        print(\"Objective Statistics:\")\n",
    "        print(f\"  KL Divergence (objective/kl): {stats['objective/kl']}\")\n",
    "        print(f\"  KL Coefficient (objective/kl_coef): {stats['objective/kl_coef']}\")\n",
    "        print(f\"  Entropy (objective/entropy): {stats['objective/entropy']}\\n\")\n",
    "        \n",
    "        print(\"PPO Losses (Related to Minimizing Objective Function):\")\n",
    "        print(f\"  Policy Loss (ppo/loss/policy): {stats['ppo/loss/policy']}\")\n",
    "        print(f\"  Value Loss (ppo/loss/value): {stats['ppo/loss/value']}\")\n",
    "        print(f\"  Total Loss (ppo/loss/total): {stats['ppo/loss/total']}\\n\")\n",
    "        \n",
    "        print(\"PPO Policy Statistics:\")\n",
    "        print(f\"  Policy Entropy (ppo/policy/entropy): {stats['ppo/policy/entropy']}\")\n",
    "        print(f\"  Approx KL (ppo/policy/approxkl): {stats['ppo/policy/approxkl']}\")\n",
    "        print(f\"  Clip Fraction (ppo/policy/clipfrac): {stats['ppo/policy/clipfrac']}\\n\")\n",
    "    else:\n",
    "        print(\"Reward and Value Function Estimation:\")\n",
    "        print(f\"  Mean Non-Score Reward (ppo/mean_non_score_reward): {stats['ppo/mean_non_score_reward']}\")\n",
    "        print(f\"  Mean Scores (ppo/mean_scores): {stats['ppo/mean_scores']}\")\n",
    "        print(f\"  Std Scores (ppo/std_scores): {stats['ppo/std_scores']}\")\n",
    "        print(f\"  Value Prediction (ppo/val/vpred): {stats['ppo/val/vpred']}\")\n",
    "        print(f\"  Value Prediction Error (ppo/val/error): {stats['ppo/val/error']}\")\n",
    "        print(f\"  Value Prediction Variance (ppo/val/var): {stats['ppo/val/var']}\")\n",
    "        print(f\"  Value Prediction Mean (ppo/val/mean): {stats['ppo/val/mean']}\")\n",
    "        print(f\"  Explained Variance (ppo/val/var_explained): {stats['ppo/val/var_explained']}\\n\")\n",
    "    \n",
    "    print(\"Token Lengths:\")\n",
    "    print(f\"  Queries Length Mean (tokens/queries_len_mean): {stats['tokens/queries_len_mean']}\")\n",
    "    print(f\"  Responses Length Mean (tokens/responses_len_mean): {stats['tokens/responses_len_mean']}\\n\")\n",
    "    \n",
    "    print(\"Time Statistics:\")\n",
    "    print(f\"  Total Time (time/ppo/total): {stats['time/ppo/total']} seconds\\n\")\n",
    "\n",
    "# Example usage with the provided stats and the flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba38231",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=\"lvwerra/gpt2-imdb\",\n",
    "    learning_rate=1.41e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d572883",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_kwargs = {\"top_k\":None, \"function_to_apply\": \"none\", \"batch_size\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21192251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"imdb\"\n",
    "ds = load_dataset(dataset_name, split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "for sample in range(N):\n",
    "    print('text',ds[sample]['text'])\n",
    "    print('label',ds[sample]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_min_text_length, input_max_text_length = 2, 8\n",
    "input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "input_size\n",
    "sample=ds[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "sample[\"input_ids\"]\n",
    "sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "sample[\"query\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dde7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(tokenize, batched=False)\n",
    "ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64490cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(ds):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Review: {sample['review']}\")\n",
    "    print(f\"Input IDs: {sample['input_ids']}\")\n",
    "    print(f\"Query: {sample['query']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ds)\n",
    "dataset_name=\"imdb\"\n",
    "ds = load_dataset(dataset_name, split=\"train\")\n",
    "ds = ds.rename_columns({\"text\": \"review\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8,tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52882482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'input_ids': [1, 2, 3, 4], 'query': \"sample text\", 'review': \"This is a sample review.\"},\n",
    "    {'input_ids': [5, 6, 7, 8], 'query': \"another sample\", 'review': \"Another sample review.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = collator(data)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)\n",
    "print(\"ppo_trainer object \",ppo_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece06926",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ab66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this movie was really bad!!\"\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c266c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this movie was really good!!\"\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c56a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(ppo_trainer.dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the first two  sample in the batch\n",
    "batch = {key: batch[key][0:2] for key in batch}\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418c1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tensors =  batch[\"input_ids\"]\n",
    "query_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad703a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text = lambda response:''.join([tokenizer.decode(r.squeeze()) for r in response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text(query_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": 50256,\n",
    "}\n",
    "generation_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531af4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_len = output_length_sampler()\n",
    "gen_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "generation_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea475b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=query_tensors[0]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f98a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d231e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query:\",get_text(query))\n",
    "print(\"response:\", get_text(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensors.append(response.squeeze()[-gen_len:])\n",
    "print(\"newly generated tokens form response:\", get_text(response_tensors[-gen_len:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=query_tensors[1]\n",
    "gen_len = output_length_sampler()\n",
    "generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "tokenizer.decode(response.squeeze()[-gen_len:], skip_special_tokens=True)\n",
    "print(\"query:\",get_text(query))\n",
    "print(\"response ouput :\", get_text(response_tensors))\n",
    "response_tensors.append(response.squeeze()[-gen_len:])\n",
    "print(\"newly generated tokens form response:\", get_text(response_tensors[-gen_len:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a88d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "batch[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37739dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "pipe_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d579593",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scores = [\n",
    "    item[\"score\"]\n",
    "    for output in pipe_outputs\n",
    "    for item in output\n",
    "    if item[\"label\"] == \"POSITIVE\"\n",
    "]\n",
    "rewards = [torch.tensor(score) for score in positive_scores]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea157889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query:\", get_text(query_tensors))\n",
    "print(\"\\n\")\n",
    "print(\"response:\", get_text(response_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c57be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "query_tensors = pad_list_to_batch_size(query_tensors, batch_size, pad_token_id)\n",
    "\n",
    "response_tensors = pad_list_to_batch_size(response_tensors, batch_size, pad_token_id)\n",
    "rewards=rewards+[torch.tensor(0) for _ in range(batch_size-len(rewards))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37417ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = \"POSITIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e20866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "    print(f\"epoch {epoch}\")\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "    positive_scores = [\n",
    "           item[\"score\"]\n",
    "           for output in pipe_outputs\n",
    "           for item in output\n",
    "           if item[\"label\"] == sentiment\n",
    "       ]\n",
    "    rewards = [torch.tensor(score) for score in positive_scores]\n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "    \n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model_dir = \"ppo-good\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model configuration and weights\n",
    "model_1.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbaf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name\n",
    "file_name = \"ppo-good-tar.gz\"\n",
    "\n",
    "# Open the tar.gz file\n",
    "with tarfile.open(file_name, \"r:gz\") as tar:\n",
    "    # Extract all the contents into the current directory\n",
    "    tar.extractall()\n",
    "\n",
    "print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"ppov3new1\"\n",
    "model_1 = AutoModelForCausalLMWithValueHead.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Load training stats\n",
    "file_name = \"ppo-good.pkl\"\n",
    "with open(file_name, 'rb') as f:\n",
    "    all_stats = pickle.load(f)\n",
    "\n",
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = [stat['ppo/loss/total'] for stat in all_stats]\n",
    "reward_values = [stat['ppo/mean_scores'] for stat in all_stats]\n",
    "\n",
    "# Plotting the loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss_values, label='Total Loss', color='b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('PPO Training Loss over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plotting the rewards\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(reward_values, label='Mean Reward', color='g')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('PPO Mean Reward over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce49d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Set the pipeline device\n",
    "pipeline_device = 0 if device.type == \"cuda\" else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e10448",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"min_length\": -1, \"max_new_tokens\":20, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}\n",
    "def generate_some_text(input_text,my_model):\n",
    "# Tokenize the input text\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    generated_ids = my_model.generate(input_ids,**gen_kwargs )\n",
    "\n",
    "    # Decode the generated text\n",
    "    generated_text_ = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422afcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Once upon a time in a land far\"\n",
    "\n",
    "generated_text=generate_some_text(input_text,model_1)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32533456",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_outputs = sentiment_pipe(generated_text, **sent_kwargs)\n",
    "pipe_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c41157",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = generate_some_text(input_text,ref_model)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_on_dataset(model, ref_model, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler):\n",
    "    gen_kwargs = {\n",
    "        \"min_length\": -1, \n",
    "        \"top_k\": 0.0, \n",
    "        \"top_p\": 1.0, \n",
    "        \"do_sample\": True, \n",
    "        \"pad_token_id\": tokenizer.eos_token_id\n",
    "    }\n",
    "    \n",
    "    bs = 16\n",
    "    game_data = dict()\n",
    "    dataset.set_format(\"pandas\")\n",
    "    df_batch = dataset[:].sample(bs)\n",
    "    game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "    query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "    response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "    # Get maximum position embeddings for both models\n",
    "    max_position_embeddings_ref = ref_model.config.max_position_embeddings\n",
    "    max_position_embeddings_model = model.config.max_position_embeddings\n",
    "\n",
    "    for i in range(bs):\n",
    "        gen_len = output_length_sampler()\n",
    "\n",
    "        # Convert query tensors to input IDs\n",
    "        input_ids = torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device)\n",
    "\n",
    "        # ********** Process for ref_model **********\n",
    "        total_length_ref = input_ids.shape[-1] + gen_len\n",
    "        if total_length_ref > max_position_embeddings_ref:\n",
    "            # Truncate input_ids to fit within the max length\n",
    "            max_input_length_ref = max_position_embeddings_ref - gen_len\n",
    "            input_ids_ref = input_ids[:, -max_input_length_ref:]\n",
    "            total_length_ref = input_ids_ref.shape[-1] + gen_len\n",
    "        else:\n",
    "            input_ids_ref = input_ids\n",
    "        \n",
    "        output = ref_model.generate(\n",
    "            torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "            max_new_tokens=gen_len, \n",
    "            **gen_kwargs\n",
    "        ).squeeze()[-gen_len:]\n",
    "        response_tensors_ref.append(output)\n",
    "\n",
    "        # ********** Process for model **********\n",
    "        total_length_model = input_ids.shape[-1] + gen_len\n",
    "        if total_length_model > max_position_embeddings_model:\n",
    "            max_input_length_model = max_position_embeddings_model - gen_len\n",
    "            input_ids_model = input_ids[:, -max_input_length_model:]\n",
    "            total_length_model = input_ids_model.shape[-1] + gen_len\n",
    "        else:\n",
    "            input_ids_model = input_ids\n",
    "        \n",
    "        output = model.generate(\n",
    "            torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "            max_new_tokens=gen_len, \n",
    "            **gen_kwargs\n",
    "        ).squeeze()[-gen_len:]\n",
    "        response_tensors.append(output)\n",
    "\n",
    "    game_data[\"response with NEGATIVE sentiment\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "    game_data[\"response with POSITIVE sentiment\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "    texts_before = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response with NEGATIVE sentiment\"])]\n",
    "    game_data[\"rewards (NEGATIVE sentiment)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts_before, **sent_kwargs)]\n",
    "\n",
    "    texts_after = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response with POSITIVE sentiment\"])]\n",
    "    game_data[\"rewards (POSITIVE sentiment)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts_after, **sent_kwargs)]\n",
    "\n",
    "    df_results = pd.DataFrame(game_data)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = compare_models_on_dataset(model_1, ref_model, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f660f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae826fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "    print(f\"epoch {epoch}\")\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "    negative_scores = [\n",
    "           item[\"score\"]\n",
    "           for output in pipe_outputs\n",
    "           for item in output\n",
    "           if item[\"label\"] == sentiment\n",
    "       ]\n",
    "    rewards = [torch.tensor(score) for score in negative_scores]\n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "    \n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model_dir = \"ppo-bad\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model configuration and weights\n",
    "model_0.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501956c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "# File name\n",
    "file_name = \"ppo-bad-tar.gz\"\n",
    "\n",
    "# Open the tar.gz file\n",
    "with tarfile.open(file_name, \"r:gz\") as tar:\n",
    "    # Extract all the contents into the current directory\n",
    "    tar.extractall()\n",
    "\n",
    "print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "model_dir = \"ppov3new_bad1\"\n",
    "model_0 = AutoModelForCausalLMWithValueHead.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Load training stats\n",
    "file_name = \"ppo-bad.pkl\"\n",
    "with open(file_name, 'rb') as f:\n",
    "    all_stats = pickle.load(f)\n",
    "\n",
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93bd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = compare_models_on_dataset(model_0, ref_model, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c640844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = compare_models_on_dataset(model_0, model_1, dataset, tokenizer, sentiment_pipe, sent_kwargs, device, output_length_sampler)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

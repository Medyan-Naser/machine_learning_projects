{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user torch==2.3.1 torchtext==0.17.2\n",
    "!pip install --user datasets==3.2.0\n",
    "!pip install --user trl==0.11\n",
    "!pip install --user transformers==4.43.4\n",
    "!pip install --user nltk==3.9.1 rouge_score==0.1.2\n",
    "!pip install --user matplotlib==3.10.0 \n",
    "!pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e64a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer,AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "import os\n",
    "\n",
    "import tarfile\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Disable warnings for a cleaner notebook or console experience\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842df524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Save a dictionary to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The dictionary to save.\n",
    "        file_path (str): The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Data successfully saved to {file_path}\")\n",
    "    \n",
    "    \n",
    "def load_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The data loaded from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8365fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_to_length(tensor, length, pad_token_id):\n",
    "    padding_length = length - tensor.size(0)\n",
    "    if padding_length > 0:\n",
    "        padding = torch.full((padding_length,), pad_token_id, dtype=torch.long, device=tensor.device)\n",
    "        return torch.cat((tensor, padding))\n",
    "    return tensor\n",
    "\n",
    "def pad_list_to_batch_size(tensors, batch_size, pad_token_id):\n",
    "    max_length = max(t.size(0) for t in tensors)\n",
    "    padded_tensors = [pad_sequence_to_length(t, max_length, pad_token_id) for t in tensors]\n",
    "\n",
    "    # Add additional padding-only tensors if needed\n",
    "    while len(padded_tensors) < batch_size:\n",
    "        padded_tensors.append(torch.full((max_length,), pad_token_id, dtype=torch.long, device=tensors[0].device))\n",
    "\n",
    "    return padded_tensors[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c23e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ppo_stats(stats, related_to_objective=False):\n",
    "    print(\"PPO Training Statistics\\n\")\n",
    "\n",
    "    if related_to_objective:\n",
    "        print(\"Objective Statistics:\")\n",
    "        print(f\"  KL Divergence (objective/kl): {stats['objective/kl']}\")\n",
    "        print(f\"  KL Coefficient (objective/kl_coef): {stats['objective/kl_coef']}\")\n",
    "        print(f\"  Entropy (objective/entropy): {stats['objective/entropy']}\\n\")\n",
    "        \n",
    "        print(\"PPO Losses (Related to Minimizing Objective Function):\")\n",
    "        print(f\"  Policy Loss (ppo/loss/policy): {stats['ppo/loss/policy']}\")\n",
    "        print(f\"  Value Loss (ppo/loss/value): {stats['ppo/loss/value']}\")\n",
    "        print(f\"  Total Loss (ppo/loss/total): {stats['ppo/loss/total']}\\n\")\n",
    "        \n",
    "        print(\"PPO Policy Statistics:\")\n",
    "        print(f\"  Policy Entropy (ppo/policy/entropy): {stats['ppo/policy/entropy']}\")\n",
    "        print(f\"  Approx KL (ppo/policy/approxkl): {stats['ppo/policy/approxkl']}\")\n",
    "        print(f\"  Clip Fraction (ppo/policy/clipfrac): {stats['ppo/policy/clipfrac']}\\n\")\n",
    "    else:\n",
    "        print(\"Reward and Value Function Estimation:\")\n",
    "        print(f\"  Mean Non-Score Reward (ppo/mean_non_score_reward): {stats['ppo/mean_non_score_reward']}\")\n",
    "        print(f\"  Mean Scores (ppo/mean_scores): {stats['ppo/mean_scores']}\")\n",
    "        print(f\"  Std Scores (ppo/std_scores): {stats['ppo/std_scores']}\")\n",
    "        print(f\"  Value Prediction (ppo/val/vpred): {stats['ppo/val/vpred']}\")\n",
    "        print(f\"  Value Prediction Error (ppo/val/error): {stats['ppo/val/error']}\")\n",
    "        print(f\"  Value Prediction Variance (ppo/val/var): {stats['ppo/val/var']}\")\n",
    "        print(f\"  Value Prediction Mean (ppo/val/mean): {stats['ppo/val/mean']}\")\n",
    "        print(f\"  Explained Variance (ppo/val/var_explained): {stats['ppo/val/var_explained']}\\n\")\n",
    "    \n",
    "    print(\"Token Lengths:\")\n",
    "    print(f\"  Queries Length Mean (tokens/queries_len_mean): {stats['tokens/queries_len_mean']}\")\n",
    "    print(f\"  Responses Length Mean (tokens/responses_len_mean): {stats['tokens/responses_len_mean']}\\n\")\n",
    "    \n",
    "    print(\"Time Statistics:\")\n",
    "    print(f\"  Total Time (time/ppo/total): {stats['time/ppo/total']} seconds\\n\")\n",
    "\n",
    "# Example usage with the provided stats and the flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba38231",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=\"lvwerra/gpt2-imdb\",\n",
    "    learning_rate=1.41e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d572883",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_kwargs = {\"top_k\":None, \"function_to_apply\": \"none\", \"batch_size\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21192251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"imdb\"\n",
    "ds = load_dataset(dataset_name, split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "for sample in range(N):\n",
    "    print('text',ds[sample]['text'])\n",
    "    print('label',ds[sample]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_min_text_length, input_max_text_length = 2, 8\n",
    "input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "input_size\n",
    "sample=ds[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "sample[\"input_ids\"]\n",
    "sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "sample[\"query\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dde7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(tokenize, batched=False)\n",
    "ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64490cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(ds):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Review: {sample['review']}\")\n",
    "    print(f\"Input IDs: {sample['input_ids']}\")\n",
    "    print(f\"Query: {sample['query']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ds)\n",
    "dataset_name=\"imdb\"\n",
    "ds = load_dataset(dataset_name, split=\"train\")\n",
    "ds = ds.rename_columns({\"text\": \"review\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8,tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52882482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'input_ids': [1, 2, 3, 4], 'query': \"sample text\", 'review': \"This is a sample review.\"},\n",
    "    {'input_ids': [5, 6, 7, 8], 'query': \"another sample\", 'review': \"Another sample review.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = collator(data)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)\n",
    "print(\"ppo_trainer object \",ppo_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece06926",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ab66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this movie was really bad!!\"\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c266c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this movie was really good!!\"\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c56a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(ppo_trainer.dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the first two  sample in the batch\n",
    "batch = {key: batch[key][0:2] for key in batch}\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418c1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tensors =  batch[\"input_ids\"]\n",
    "query_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad703a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text = lambda response:''.join([tokenizer.decode(r.squeeze()) for r in response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text(query_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": 50256,\n",
    "}\n",
    "generation_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531af4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_len = output_length_sampler()\n",
    "gen_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "generation_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea475b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=query_tensors[0]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f98a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d231e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query:\",get_text(query))\n",
    "print(\"response:\", get_text(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensors.append(response.squeeze()[-gen_len:])\n",
    "print(\"newly generated tokens form response:\", get_text(response_tensors[-gen_len:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=query_tensors[1]\n",
    "gen_len = output_length_sampler()\n",
    "generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "tokenizer.decode(response.squeeze()[-gen_len:], skip_special_tokens=True)\n",
    "print(\"query:\",get_text(query))\n",
    "print(\"response ouput :\", get_text(response_tensors))\n",
    "response_tensors.append(response.squeeze()[-gen_len:])\n",
    "print(\"newly generated tokens form response:\", get_text(response_tensors[-gen_len:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a88d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "batch[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37739dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "pipe_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d579593",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scores = [\n",
    "    item[\"score\"]\n",
    "    for output in pipe_outputs\n",
    "    for item in output\n",
    "    if item[\"label\"] == \"POSITIVE\"\n",
    "]\n",
    "rewards = [torch.tensor(score) for score in positive_scores]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea157889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query:\", get_text(query_tensors))\n",
    "print(\"\\n\")\n",
    "print(\"response:\", get_text(response_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c57be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "query_tensors = pad_list_to_batch_size(query_tensors, batch_size, pad_token_id)\n",
    "\n",
    "response_tensors = pad_list_to_batch_size(response_tensors, batch_size, pad_token_id)\n",
    "rewards=rewards+[torch.tensor(0) for _ in range(batch_size-len(rewards))]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
